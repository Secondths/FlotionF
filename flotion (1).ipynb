{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8707479,"sourceType":"datasetVersion","datasetId":5223133}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom tensorflow.keras.utils import to_categorical\n\n# Constants\nIMAGE_SIZE = (128, 128)\nDATASET_PATH = '/kaggle/input/indonesian-flora/train'\n\n# Load dataset\ndef load_dataset(dataset_path):\n    images = []\n    labels = []\n    class_names = os.listdir(dataset_path)\n    class_dict = {class_name: idx for idx, class_name in enumerate(class_names)}\n\n    for class_name in class_names:\n        class_path = os.path.join(dataset_path, class_name)\n        for img_name in os.listdir(class_path):\n            img_path = os.path.join(class_path, img_name)\n            img = cv2.imread(img_path)\n            img = cv2.resize(img, IMAGE_SIZE)\n            images.append(img)\n            labels.append(class_dict[class_name])\n    \n    images = np.array(images)\n    labels = to_categorical(np.array(labels))\n    \n    return images, labels, class_names\n\nif __name__ == \"__main__\":\n    images, labels, class_names = load_dataset(DATASET_PATH)\n    np.save('images.npy', images)\n    np.save('labels.npy', labels)\n    np.save('class_names.npy', class_names)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-22T09:57:26.061350Z","iopub.execute_input":"2024-07-22T09:57:26.061742Z","iopub.status.idle":"2024-07-22T09:57:57.415673Z","shell.execute_reply.started":"2024-07-22T09:57:26.061707Z","shell.execute_reply":"2024-07-22T09:57:57.414696Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-07-22 09:57:28.268091: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-22 09:57:28.268216: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-22 09:57:28.411661: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nlibpng warning: iCCP: known incorrect sRGB profile\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\nimport joblib\n\n# Constants\nIMAGE_SIZE = (128, 128)\n\n# Load dataset\nimages = np.load('images.npy')\nlabels = np.load('labels.npy')\nclass_names = np.load('class_names.npy', allow_pickle=True)\n\n# Split dataset\nX_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n\n# Train KNN model\nX_train_flat = X_train.reshape(X_train.shape[0], -1)\nX_test_flat = X_test.reshape(X_test.shape[0], -1)\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train_flat, np.argmax(y_train, axis=1))\n\n# Save KNN model\njoblib.dump(knn, 'knn_model.pkl')\n\n# Define and train CNN model\ncnn = Sequential([\n    Conv2D(32, (3, 3), activation='relu', input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3)),\n    MaxPooling2D((2, 2)),\n    Conv2D(64, (3, 3), activation='relu'),\n    MaxPooling2D((2, 2)),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dense(len(class_names), activation='softmax')\n])\n\ncnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\ncnn.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n\n# Save CNN model\ncnn.save('cnn_model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-22T10:06:12.863187Z","iopub.execute_input":"2024-07-22T10:06:12.864099Z","iopub.status.idle":"2024-07-22T10:09:27.987525Z","shell.execute_reply.started":"2024-07-22T10:06:12.864055Z","shell.execute_reply":"2024-07-22T10:09:27.986408Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 386ms/step - accuracy: 0.2961 - loss: 284.5932 - val_accuracy: 0.4515 - val_loss: 1.3743\nEpoch 2/10\n\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 382ms/step - accuracy: 0.6530 - loss: 1.0233 - val_accuracy: 0.6224 - val_loss: 1.1700\nEpoch 3/10\n\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 373ms/step - accuracy: 0.8614 - loss: 0.4479 - val_accuracy: 0.6786 - val_loss: 1.0764\nEpoch 4/10\n\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 380ms/step - accuracy: 0.9658 - loss: 0.1494 - val_accuracy: 0.6786 - val_loss: 1.3087\nEpoch 5/10\n\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 374ms/step - accuracy: 0.9745 - loss: 0.0870 - val_accuracy: 0.6888 - val_loss: 1.4336\nEpoch 6/10\n\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 381ms/step - accuracy: 0.9917 - loss: 0.0411 - val_accuracy: 0.6837 - val_loss: 1.3823\nEpoch 7/10\n\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 387ms/step - accuracy: 0.9920 - loss: 0.0738 - val_accuracy: 0.6811 - val_loss: 1.5539\nEpoch 8/10\n\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 370ms/step - accuracy: 0.9963 - loss: 0.0313 - val_accuracy: 0.6760 - val_loss: 1.8658\nEpoch 9/10\n\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 376ms/step - accuracy: 0.9931 - loss: 0.0365 - val_accuracy: 0.7015 - val_loss: 1.6499\nEpoch 10/10\n\u001b[1m49/49\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 370ms/step - accuracy: 0.9975 - loss: 0.0173 - val_accuracy: 0.6480 - val_loss: 2.0685\n","output_type":"stream"}]}]}